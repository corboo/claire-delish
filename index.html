<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Claire Delish - AI Cooking Companion</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            color: #fff;
        }
        .container { max-width: 1100px; width: 100%; }
        header { text-align: center; margin-bottom: 15px; }
        h1 { font-size: 2rem; color: #FF6B35; margin-bottom: 5px; }
        .subtitle { color: #888; font-size: 0.9rem; }
        
        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }
        button {
            padding: 12px 24px;
            font-size: 0.95rem;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.2s;
            font-weight: 600;
        }
        .btn-primary { background: #FF6B35; color: white; }
        .btn-primary:hover { background: #E55A2B; transform: translateY(-2px); }
        .btn-primary:disabled { background: #555; cursor: not-allowed; transform: none; }
        .btn-secondary { background: rgba(255,255,255,0.1); color: #fff; border: 2px solid rgba(255,255,255,0.3); }
        .btn-secondary:hover { background: rgba(255,255,255,0.2); }
        .btn-secondary.active { background: rgba(255,107,53,0.3); border-color: #FF6B35; }
        .btn-danger { background: #dc3545; color: white; }
        .btn-danger:hover { background: #c82333; }
        .hidden { display: none !important; }
        
        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            max-width: 800px;
            margin: 0 auto;
        }
        @media (max-width: 600px) {
            .main-content { grid-template-columns: 1fr; }
        }
        
        .panel {
            background: rgba(255,255,255,0.05);
            border-radius: 16px;
            padding: 15px;
        }
        
        .panel h3 {
            color: #FF6B35;
            font-size: 0.9rem;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .avatar-container {
            position: relative;
            width: 100%;
            aspect-ratio: 1;
            max-width: 280px;
            margin: 0 auto;
            border-radius: 12px;
            overflow: hidden;
            background: #000;
        }
        
        .avatar-img, .avatar-video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 12px;
        }
        
        .avatar-video {
            display: none;
        }
        
        .avatar-video.active {
            display: block;
        }
        
        .avatar-img.hidden-avatar {
            display: none;
        }
        
        .video-loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0,0,0,0.7);
            padding: 10px 20px;
            border-radius: 20px;
            font-size: 0.8rem;
            display: none;
        }
        
        .video-loading.active {
            display: block;
        }
        
        .avatar-status {
            text-align: center;
            margin-top: 10px;
            font-size: 0.85rem;
            color: #888;
        }
        
        .avatar-status.speaking { color: #FF6B35; }
        .avatar-status.thinking { color: #ffc107; }
        .avatar-status.listening { color: #28a745; }
        
        .transcript {
            max-height: 350px;
            overflow-y: auto;
        }
        
        .message {
            padding: 10px 12px;
            margin-bottom: 8px;
            border-radius: 12px;
            font-size: 0.9rem;
        }
        .message.user { background: rgba(0,123,255,0.2); margin-left: 15%; }
        .message.claire { background: rgba(255,107,53,0.2); margin-right: 15%; }
        .message.system { background: rgba(255,255,255,0.1); font-style: italic; font-size: 0.8rem; text-align: center; }
        .message .label { font-size: 0.7rem; color: #888; margin-bottom: 3px; }
        
        footer {
            text-align: center;
            color: #555;
            font-size: 0.75rem;
            margin-top: 15px;
        }
        
        .status-badge {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 4px 12px;
            border-radius: 15px;
            font-size: 0.75rem;
            background: rgba(255,255,255,0.1);
        }
        .status-badge .dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #888;
        }
        .status-badge.connected .dot { background: #28a745; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üç≥ Claire Delish</h1>
            <p class="subtitle">AI cooking companion with perfect lip-sync</p>
        </header>

        <div class="controls">
            <button class="btn-primary" id="startBtn">üéôÔ∏è Start Cooking Session</button>
            <button class="btn-danger hidden" id="endBtn">‚èπÔ∏è End Session</button>
            <button class="btn-secondary hidden" id="muteBtn">üîá Mute Mic</button>
            <button class="btn-secondary hidden" id="cameraBtn">üì∑ Enable Camera</button>
        </div>
        
        <!-- Hidden camera for expression analysis -->
        <video id="userCamera" style="display:none;" autoplay playsinline muted></video>

        <div class="main-content">
            <div class="panel">
                <h3>üë©‚Äçüç≥ Claire</h3>
                <div class="avatar-container">
                    <img id="avatarImg" class="avatar-img" src="assets/chef-avatar.png" alt="Claire">
                    <video id="avatarVideo" class="avatar-video" autoplay playsinline muted></video>
                    <div class="video-loading" id="videoLoading">üç≥ Still cooking... almost done!</div>
                </div>
                <div class="avatar-status" id="claireStatus">Ready to cook!</div>
            </div>

            <div class="panel">
                <h3>üí¨ Conversation</h3>
                <div class="transcript" id="messages"></div>
            </div>

        </div>

        <footer>
            Powered by Hume AI + D-ID | Perfect Lip-Sync Edition | Inception Point AI
        </footer>
    </div>

    <script>
        // ========== Configuration ==========
        const CONFIG = {
            HUME_API_KEY: 'Qpo16RO78hsfKE37KnJM7mlXBp1pnGaXVUQ0x36nNIbmgjUp',
            HUME_CONFIG_ID: '5e4ab7a7-c3e8-4539-b2a3-c3cdfe69ecf4',
            DID_API_KEY: 'd2lsbGlhbUBpbmNlcHRpb25wb2ludC5haQ:HwX29E9ADq-mEFkZp2GFl'
        };

        // ========== State ==========
        let humeSocket = null;
        let micRecorder = null;
        let audioContext = null;
        let isMuted = false;
        let userCameraStream = null;
        let expressionInterval = null;
        let lastEmotionContext = '';
        
        // Audio collection for D-ID
        let currentResponseAudio = [];
        let isCollectingAudio = false;
        let videoQueue = [];
        let isProcessingVideo = false;

        // ========== DOM Elements ==========
        const startBtn = document.getElementById('startBtn');
        const endBtn = document.getElementById('endBtn');
        const muteBtn = document.getElementById('muteBtn');
        const cameraBtn = document.getElementById('cameraBtn');
        const messagesEl = document.getElementById('messages');
        const avatarImg = document.getElementById('avatarImg');
        const avatarVideo = document.getElementById('avatarVideo');
        const videoLoading = document.getElementById('videoLoading');
        const claireStatus = document.getElementById('claireStatus');
        const userCamera = document.getElementById('userCamera');

        // ========== Utilities ==========
        function setClaireStatus(status, text) {
            claireStatus.className = 'avatar-status ' + status;
            claireStatus.textContent = text;
        }

        function addMessage(role, text) {
            const div = document.createElement('div');
            div.className = 'message ' + role;
            if (role !== 'system') {
                const label = document.createElement('div');
                label.className = 'label';
                label.textContent = role === 'user' ? 'You' : 'Claire';
                div.appendChild(label);
            }
            const content = document.createElement('div');
            content.textContent = text;
            div.appendChild(content);
            messagesEl.appendChild(div);
            messagesEl.scrollTop = messagesEl.scrollHeight;
        }
        
        // Combine base64 audio chunks into a single WAV-like blob
        function combineAudioChunks(chunks) {
            // Each chunk is base64 PCM audio from Hume (24kHz, 16-bit, mono)
            const binaryChunks = chunks.map(chunk => {
                const binary = atob(chunk);
                const bytes = new Uint8Array(binary.length);
                for (let i = 0; i < binary.length; i++) {
                    bytes[i] = binary.charCodeAt(i);
                }
                return bytes;
            });
            
            // Calculate total length
            const totalLength = binaryChunks.reduce((sum, chunk) => sum + chunk.length, 0);
            
            // Combine all chunks
            const combined = new Uint8Array(totalLength);
            let offset = 0;
            for (const chunk of binaryChunks) {
                combined.set(chunk, offset);
                offset += chunk.length;
            }
            
            // Create WAV header - trying 44.1kHz
            const wavHeader = createWavHeader(combined.length, 44100, 1, 16);
            
            // Combine header and data
            const wav = new Uint8Array(wavHeader.length + combined.length);
            wav.set(wavHeader, 0);
            wav.set(combined, wavHeader.length);
            
            return wav;
        }
        
        function createWavHeader(dataLength, sampleRate, numChannels, bitsPerSample) {
            const header = new ArrayBuffer(44);
            const view = new DataView(header);
            
            const blockAlign = numChannels * bitsPerSample / 8;
            const byteRate = sampleRate * blockAlign;
            
            // RIFF header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + dataLength, true);
            writeString(view, 8, 'WAVE');
            
            // fmt chunk
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true); // chunk size
            view.setUint16(20, 1, true); // PCM
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitsPerSample, true);
            
            // data chunk
            writeString(view, 36, 'data');
            view.setUint32(40, dataLength, true);
            
            return new Uint8Array(header);
        }
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // ========== Hume EVI (Voice Chat) ==========
        async function startHumeEVI() {
            setClaireStatus('thinking', 'Connecting...');
            
            const micStream = await navigator.mediaDevices.getUserMedia({ 
                audio: { 
                    sampleRate: 16000, 
                    channelCount: 1, 
                    echoCancellation: true, 
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });
            
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
            
            const wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${CONFIG.HUME_API_KEY}&config_id=${CONFIG.HUME_CONFIG_ID}`;
            humeSocket = new WebSocket(wsUrl);
            
            humeSocket.onopen = () => {
                setClaireStatus('listening', 'üé§ Listening...');
                startBtn.classList.add('hidden');
                endBtn.classList.remove('hidden');
                muteBtn.classList.remove('hidden');
                cameraBtn.classList.remove('hidden');
                startMicCapture(micStream);
                addMessage('claire', "Hey there! I'm Claire, your AI cooking companion. What are we making today? Enable your camera so I can see what you're working with!");
            };
            
            humeSocket.onmessage = (event) => {
                const msg = JSON.parse(event.data);
                handleHumeMessage(msg);
            };
            
            humeSocket.onerror = (error) => {
                console.error('Hume EVI error:', error);
                setClaireStatus('', 'Connection error');
            };
            
            humeSocket.onclose = () => cleanup();
        }
        
        function handleHumeMessage(msg) {
            switch (msg.type) {
                case 'user_message':
                    if (msg.message?.content) {
                        addMessage('user', msg.message.content);
                    }
                    break;
                    
                case 'assistant_message':
                    if (msg.message?.content) {
                        addMessage('claire', msg.message.content);
                        // Start collecting audio for this response
                        isCollectingAudio = true;
                        currentResponseAudio = [];
                        setClaireStatus('thinking', 'üí≠ Preparing response...');
                    }
                    break;
                    
                case 'audio_output':
                    // Play audio immediately AND collect for D-ID
                    playAudioChunk(msg.data);
                    if (isCollectingAudio) {
                        currentResponseAudio.push(msg.data);
                    }
                    break;
                    
                case 'assistant_end':
                    // Response complete - send collected audio to D-ID
                    if (isCollectingAudio && currentResponseAudio.length > 0) {
                        isCollectingAudio = false;
                        const audioChunks = [...currentResponseAudio];
                        currentResponseAudio = [];
                        
                        // Queue video generation with collected audio
                        videoQueue.push(audioChunks);
                        processVideoQueue();
                    }
                    break;
            }
        }
        
        // Play audio chunk immediately
        function playAudioChunk(base64Audio) {
            try {
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                audioContext.decodeAudioData(bytes.buffer.slice(0), (audioBuffer) => {
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start();
                    setClaireStatus('speaking', 'üó£Ô∏è Speaking...');
                }, (err) => {
                    console.log('Audio decode error:', err);
                });
            } catch (e) {
                console.error('Audio play error:', e);
            }
        }
        
        function startMicCapture(stream) {
            const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
                ? 'audio/webm;codecs=opus' : 'audio/webm';
            
            micRecorder = new MediaRecorder(stream, { mimeType });
            
            micRecorder.ondataavailable = async (event) => {
                if (event.data.size > 0 && humeSocket?.readyState === WebSocket.OPEN && !isMuted) {
                    const reader = new FileReader();
                    reader.onloadend = () => {
                        const base64 = reader.result.split(',')[1];
                        humeSocket.send(JSON.stringify({ type: 'audio_input', data: base64 }));
                    };
                    reader.readAsDataURL(event.data);
                }
            };
            
            micRecorder.start(100);
        }

        // ========== D-ID Video Generation with Hume Audio ==========
        async function processVideoQueue() {
            if (isProcessingVideo || videoQueue.length === 0) return;
            
            isProcessingVideo = true;
            const audioChunks = videoQueue.shift();
            
            videoLoading.classList.add('active');
            setClaireStatus('speaking', 'üé¨ Generating lip-sync...');
            
            try {
                // Combine audio chunks into WAV
                const wavData = combineAudioChunks(audioChunks);
                const audioBlob = new Blob([wavData], { type: 'audio/wav' });
                
                // Upload audio to D-ID
                const audioFormData = new FormData();
                audioFormData.append('audio', audioBlob, 'speech.wav');
                
                const uploadResponse = await fetch('https://api.d-id.com/audios', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Basic ${CONFIG.DID_API_KEY}`
                    },
                    body: audioFormData
                });
                
                if (!uploadResponse.ok) {
                    throw new Error(`Audio upload failed: ${uploadResponse.status}`);
                }
                
                const uploadData = await uploadResponse.json();
                const audioUrl = uploadData.url;
                
                console.log('Audio uploaded:', audioUrl);
                
                // Create talk with the uploaded audio
                const talkResponse = await fetch('https://api.d-id.com/talks', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Basic ${CONFIG.DID_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        source_url: 'https://corboo.github.io/claire-delish/assets/chef-avatar.png',
                        script: {
                            type: 'audio',
                            audio_url: audioUrl
                        },
                        config: {
                            fluent: true
                        }
                    })
                });
                
                if (!talkResponse.ok) {
                    throw new Error(`Talk creation failed: ${talkResponse.status}`);
                }
                
                const talkData = await talkResponse.json();
                const talkId = talkData.id;
                
                console.log('Talk created:', talkId);
                
                // Poll for completion
                for (let i = 0; i < 60; i++) {
                    await new Promise(r => setTimeout(r, 1000));
                    
                    const statusRes = await fetch(`https://api.d-id.com/talks/${talkId}`, {
                        headers: { 'Authorization': `Basic ${CONFIG.DID_API_KEY}` }
                    });
                    
                    const statusData = await statusRes.json();
                    console.log('Talk status:', statusData.status);
                    
                    if (statusData.status === 'done') {
                        // Play the video with audio (perfect sync!)
                        avatarVideo.src = statusData.result_url;
                        avatarVideo.classList.add('active');
                        avatarImg.classList.add('hidden-avatar');
                        videoLoading.classList.remove('active');
                        
                        setClaireStatus('speaking', 'üó£Ô∏è Speaking...');
                        
                        avatarVideo.onended = () => {
                            setClaireStatus('listening', 'üé§ Listening...');
                        };
                        
                        await avatarVideo.play();
                        break;
                    } else if (statusData.status === 'error') {
                        throw new Error('D-ID generation failed: ' + (statusData.error?.message || 'Unknown'));
                    }
                }
            } catch (e) {
                console.error('D-ID error:', e);
                videoLoading.classList.remove('active');
                setClaireStatus('listening', 'üé§ Listening...');
                addMessage('system', 'Video generation failed, but Claire is still listening!');
            }
            
            isProcessingVideo = false;
            processVideoQueue();
        }

        // ========== Camera & Expression Analysis (Hidden) ==========
        async function enableCamera() {
            try {
                userCameraStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'user', width: 320, height: 240 } 
                });
                userCamera.srcObject = userCameraStream;
                cameraBtn.textContent = 'üì∑ Camera On';
                cameraBtn.classList.add('active');
                startExpressionAnalysis();
                addMessage('system', 'Camera enabled - Claire can see your expressions');
            } catch (e) {
                addMessage('system', 'Could not access camera');
            }
        }
        
        function disableCamera() {
            if (userCameraStream) {
                userCameraStream.getTracks().forEach(t => t.stop());
                userCameraStream = null;
            }
            if (expressionInterval) {
                clearInterval(expressionInterval);
                expressionInterval = null;
            }
            userCamera.srcObject = null;
            cameraBtn.textContent = 'üì∑ Enable Camera';
            cameraBtn.classList.remove('active');
        }
        
        function startExpressionAnalysis() {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            expressionInterval = setInterval(async () => {
                if (!userCameraStream) return;
                
                canvas.width = userCamera.videoWidth || 320;
                canvas.height = userCamera.videoHeight || 240;
                ctx.drawImage(userCamera, 0, 0);
                
                const base64 = canvas.toDataURL('image/jpeg', 0.7).split(',')[1];
                
                // Send to Hume Expression Measurement API
                try {
                    const response = await fetch('https://api.hume.ai/v0/batch/jobs', {
                        method: 'POST',
                        headers: {
                            'X-Hume-Api-Key': CONFIG.HUME_API_KEY,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            models: { face: {} },
                            urls: [`data:image/jpeg;base64,${base64}`]
                        })
                    });
                    // Note: This is simplified - full implementation would poll for results
                } catch (e) {
                    // Silent fail for expression analysis
                }
            }, 3000); // Analyze every 3 seconds
        }
        
        cameraBtn.onclick = () => {
            if (userCameraStream) {
                disableCamera();
            } else {
                enableCamera();
            }
        };

        // ========== Main Controls ==========
        startBtn.onclick = async () => {
            try {
                await startHumeEVI();
            } catch (error) {
                setClaireStatus('', 'Error: ' + error.message);
            }
        };
        
        endBtn.onclick = () => {
            addMessage('claire', "Thanks for cooking with me! üç≥");
            cleanup();
        };
        
        muteBtn.onclick = () => {
            isMuted = !isMuted;
            muteBtn.textContent = isMuted ? 'üîä Unmute' : 'üîá Mute Mic';
            muteBtn.classList.toggle('active', isMuted);
        };
        
        function cleanup() {
            if (micRecorder?.state !== 'inactive') {
                micRecorder?.stop();
                micRecorder?.stream?.getTracks().forEach(t => t.stop());
            }
            if (humeSocket) humeSocket.close();
            if (audioContext) audioContext.close();
            disableCamera();
            
            humeSocket = null;
            audioContext = null;
            micRecorder = null;
            videoQueue = [];
            currentResponseAudio = [];
            isProcessingVideo = false;
            isCollectingAudio = false;
            
            startBtn.classList.remove('hidden');
            endBtn.classList.add('hidden');
            muteBtn.classList.add('hidden');
            cameraBtn.classList.add('hidden');
            cameraToggle.classList.add('hidden');
            
            avatarVideo.classList.remove('active');
            avatarImg.classList.remove('hidden-avatar');
            userVideo.srcObject = null;
            
            setClaireStatus('', 'Session ended');
        }
    </script>
</body>
</html>
